{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "JLnD5FHh3-Bt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Non_stationary_environment():\n",
        "  def __init__(self, bid, ec, en, conversion_funcs, N, C,min_phase_duration= 10, max_phase_duration=20):\n",
        "    self.min_phase_duration=min_phase_duration\n",
        "    self.max_phase_duration=max_phase_duration\n",
        "    self.bid= bid\n",
        "    self.ec=ec\n",
        "    self.en=en\n",
        "    self.conversion_funcs= conversion_funcs\n",
        "    self.t_end_phase=np.random.randint(min_phase_duration, max_phase_duration)\n",
        "    self.actual_phase=0\n",
        "    self.num_phases=conversion_funcs.shape[0]\n",
        "    self.t=0\n",
        "    self.N=N\n",
        "    self.C=C\n",
        "\n",
        "  def perform_day(self, price: float):\n",
        "        \"\"\"\n",
        "        :param price: the price selected for the day\n",
        "        :param t: the number of the day from the start\n",
        "        :return: (num_clicks,num_conversions,adv_cost)\n",
        "        num_clicks: int - the number of clicks\n",
        "        num_conversions: int - the number of conversions\n",
        "        adv_cost: float - the advertising costs\n",
        "        \"\"\"\n",
        "        num_clicks = int(self.N(self.bid) + self.en())\n",
        "\n",
        "        conversion_samples = np.random.binomial(n=1, p=self.conversion_funcs[self.actual_phase](price), size=num_clicks)\n",
        "        num_conversions = np.sum(conversion_samples)\n",
        "\n",
        "        adv_cost = self.C(self.bid) + self.ec()\n",
        "\n",
        "        if(self.t==self.t_end_phase):\n",
        "          self.actual_phase+=1\n",
        "          self.t_end_phase+=np.random.randint(self.min_phase_duration, self.max_phase_duration)\n",
        "\n",
        "        self.t+=1\n",
        "        return num_clicks, num_conversions, adv_cost\n"
      ],
      "metadata": {
        "id": "OO-O9zXets9z"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.multiarray import ndarray\n",
        "class NonStationaryClassEnvironmentHistory:\n",
        "    \"\"\"\n",
        "    History of all the steps performed by an environment\n",
        "    Observe that it is not stored inside the environment itself, but by the learner\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, N, conversion_funcs, best_prices: ndarray, bid):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        N : callable\n",
        "            N:bid->E[number of clicks] must be applicable to arrays\n",
        "        C : callable\n",
        "            C:bid->E[payment for clicks] must be applicable to arrays\n",
        "        conversion_funcs : array of functions, one conversion for each phase\n",
        "            conversion_funcs[phase](p) = E[conversion rate at price p at phase \"phase\"]\n",
        "        best_price : float\n",
        "            the price (among the available ones) that maximizes the reward\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        None.\n",
        "\n",
        "        \"\"\"\n",
        "        self.N = N\n",
        "        self.conversion_funcs = conversion_funcs\n",
        "        self.best_prices = best_prices\n",
        "        self.chosen_prices_per_round = []\n",
        "        self.ns = []\n",
        "        self.qs = []\n",
        "        self.cs = []\n",
        "        self.phase_per_round=[]\n",
        "        self.bid=bid\n",
        "\n",
        "    def add_step(self, p: float, n: int, q: int, phase: int):\n",
        "        \"\"\"\n",
        "        Memorizes a new step (i.e., day) that has been performed\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : float\n",
        "            the chosen bid\n",
        "        p : float\n",
        "            the chosen price\n",
        "        n : int\n",
        "            the number of clicks achieved\n",
        "        q : int\n",
        "            the number of conversions achieved\n",
        "        phase: int\n",
        "            the phase between the 5 that we can have\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        None.\n",
        "\n",
        "        \"\"\"\n",
        "        self.chosen_prices_per_round.append(p)\n",
        "        self.ns.append(n)\n",
        "        self.qs.append(q)\n",
        "        self.phase_per_round.append(phase)\n",
        "\n",
        "    def reward_stats(self):\n",
        "        \"\"\"\n",
        "        These stats are computed with the expected rewards\n",
        "        (without noise)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        instantaneous_rewards : numpy array\n",
        "            the instantaneous rewards\n",
        "        instantaneous_regrets : numpy array\n",
        "            the instantaneous regrets\n",
        "        cumulative_rewards : numpy array\n",
        "            the cumulative rewards\n",
        "        cumulative_regrets : numpy array\n",
        "            the cumulative regrets\n",
        "\n",
        "        \"\"\"\n",
        "        chosen_prices_per_round  = np.array(self.chosen_prices_per_round )\n",
        "        return self.compute_reward_stats(chosen_prices_per_round, self.N, self.best_prices, self.conversion_funcs, self.phase_per_round, self.bid)\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_reward_stats(chosen_prices_per_round : np.ndarray,N: callable,\n",
        "                            best_price: float,conversion_funcs: np.ndarray, phase_per_round: np.ndarray, bid):\n",
        "        \"\"\"\n",
        "        :return:\n",
        "        instantaneous_rewards : np.ndarray\n",
        "            the instantaneous rewards for each time step\n",
        "        instantaneous_regrets : np.ndarray\n",
        "            the instantaneous regrets for each time step\n",
        "        cumulative_rewards : np.ndarray\n",
        "            the cumulative rewards for each time step\n",
        "        cumulative_regrets : np.ndarray\n",
        "            the cumulative regrets for each time step\n",
        "        \"\"\"\n",
        "\n",
        "        alphas=np.zeros(len(chosen_prices_per_round))\n",
        "        for i in range(0,len(chosen_prices_per_round )):\n",
        "          alphas[i] = conversion_funcs[phase_per_round[i]](chosen_prices_per_round[i])\n",
        "\n",
        "        # here maybe I should use the actual number of conversions and advertising costs with the noise?\n",
        "        instantaneous_rewards = alphas * chosen_prices_per_round\n",
        "\n",
        "        best_reward=np.zeros(len(chosen_prices_per_round))\n",
        "        for i in range(0,len(chosen_prices_per_round )):\n",
        "            best_reward[i] = conversion_funcs[phase_per_round[i]](best_price[phase_per_round[i]]) * best_price[phase_per_round[i]]\n",
        "\n",
        "        for phase in range(len(conversion_funcs)):\n",
        "          print(str(phase)+\". \"+str(best_price[phase]))\n",
        "        instantaneous_regrets = best_reward - instantaneous_rewards\n",
        "\n",
        "        for round in range(len(phase_per_round)):\n",
        "          print(str(round)+\"-> phase: \"+str(phase_per_round[round])+\", arm chosen: \"+ str(chosen_prices_per_round[round]))\n",
        "\n",
        "        return instantaneous_rewards, instantaneous_regrets, np.cumsum(instantaneous_rewards), np.cumsum(instantaneous_regrets)\n",
        "\n",
        "    def played_rounds(self):\n",
        "        return len(self.chosen_prices_per_round)\n",
        "\n"
      ],
      "metadata": {
        "id": "ntZXDRK2OEEx"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_price_per_phase(prices, estimated_alphas):\n",
        "  \"\"\"\n",
        "  prices: np.array\n",
        "    all the prices(arms) which can be chosen\n",
        "  estimated_alphas: np.array\n",
        "    the conversion rate estimation for each phase possible\n",
        "\n",
        "  return\n",
        "    best_price_per_phase: np.array that contains the best possible price for each phase\n",
        "  \"\"\"\n",
        "  best_price_per_phase=np.array([])\n",
        "  for alphas_phase in estimated_alphas:\n",
        "    earnings = alphas_phase * prices\n",
        "    i = np.argmax(earnings)\n",
        "    best_price_per_phase=np.append(best_price_per_phase,prices[i])\n",
        "  return best_price_per_phase"
      ],
      "metadata": {
        "id": "2i_Fzptw8MeQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Exp3Learner():\n",
        "  def __init__(self, environment: Non_stationary_environment, bid: np.ndarray, prices: np.ndarray):\n",
        "     self.env = environment\n",
        "     self.prices = prices\n",
        "     self.bid = bid\n",
        "     self._prepare_history()\n",
        "     self.estimator = BeExp3Estimator(self.prices)\n",
        "\n",
        "  def play_and_save(self, price):\n",
        "        n, q, c = self.env.perform_day(price)\n",
        "        self.history.add_step(price, n, q, self.env.actual_phase)\n",
        "        return n, q, c\n",
        "\n",
        "\n",
        "\n",
        "  def play_round(self):\n",
        "    if self.history.played_rounds() < self.prices.shape[0]:\n",
        "      p_t = self.prices[self.history.played_rounds()]\n",
        "      p_t_ind = self.history.played_rounds()\n",
        "    else:\n",
        "      p_t, p_t_ind = self.estimator.provide_arm()\n",
        "\n",
        "    n, q, c = self.play_and_save(p_t)\n",
        "    self.estimator.update_estimations(p_t_ind, q/n)\n",
        "\n",
        "\n",
        "  def _prepare_history(self):\n",
        "    alphas_est = np.array([[self.env.conversion_funcs[i](p) for p in self.prices ] for i in range(self.env.num_phases)])\n",
        "    n_est = self.env.N(self.bid)\n",
        "\n",
        "    #c_est = self.env.C(self.xs)\n",
        "    best_prices = find_best_price_per_phase(self.prices, alphas_est)\n",
        "    self.history = NonStationaryClassEnvironmentHistory(self.env.N, self.env.conversion_funcs, best_prices, self.bid)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LqhnMY38uc_U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "class BeExp3Estimator():\n",
        "  def __init__(self, prices, gamma=0.0):\n",
        "    self.gamma=gamma\n",
        "    self.weights = [1.0] * len(prices)\n",
        "    self.arm_prices=prices\n",
        "    self.probability_distribution=self.distr()\n",
        "\n",
        "  def distr(self):\n",
        "    weight_sum = float(sum(self.weights))\n",
        "    return tuple((1.0 - self.gamma) * (w / weight_sum) + (self.gamma / len(self.weights)) for w in self.weights)\n",
        "\n",
        "  def provide_arm(self):\n",
        "    drawn_price = np.random.choice(self.arm_prices, size=1, p=self.probability_distribution, replace=False)[0]\n",
        "    price_idx = np.where(self.arm_prices == drawn_price)[0]\n",
        "    return drawn_price, int(price_idx)\n",
        "\n",
        "\n",
        "  def update_estimations(self,price_idx, reward):\n",
        "\n",
        "    estimatedReward = float(reward*self.arm_prices[price_idx] / self.probability_distribution[price_idx])\n",
        "    self.weights[price_idx] = self.weights[price_idx] * math.exp(estimatedReward * self.gamma / self.arm_prices.shape[0])\n",
        "    self.probability_distribution = self.distr()"
      ],
      "metadata": {
        "id": "3qXQ6NzaiipR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main"
      ],
      "metadata": {
        "id": "bs37rzoNb5Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bid=10\n",
        "prices=np.array([5,10,20,30,40,50])\n",
        "\n",
        "C= lambda x:x**1/2\n",
        "N=lambda x: x**2\n",
        "ec= lambda: np.random.normal(0, 1)\n",
        "conv_funcs = np.array([lambda x: 1/np.sqrt(x),\n",
        "                       lambda x: 1/np.log(x+1),\n",
        "                       lambda x: np.e**(-x),\n",
        "                       lambda x: 1/(1+np.e**(-x)),\n",
        "                       lambda x:  1 / (1 + x**2)])\n",
        "\n",
        "\n",
        "\n",
        "env=Non_stationary_environment(bid, ec,ec,conv_funcs, N,C)\n",
        "learner=Exp3Learner(env, bid, prices)\n",
        "\n",
        "n_rounds=50\n",
        "for i in range(0,n_rounds):\n",
        "  learner.play_round()\n",
        "\n",
        "instantaneous_rewards, instantaneous_regrets, cumsum_instantaneous_rewards, cum_sum_instantaneous_regrets=learner.history.reward_stats()\n",
        "#print(\"cumulative regret: \"+str(cum_sum_instantaneous_regrets))"
      ],
      "metadata": {
        "id": "o7FZFZy7BWr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdd7cc5-13b5-4e47-e7b3-a5612109152e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. 50.0\n",
            "1. 50.0\n",
            "2. 5.0\n",
            "3. 50.0\n",
            "4. 5.0\n",
            "0-> phase: 0, arm chosen: 5\n",
            "1-> phase: 0, arm chosen: 10\n",
            "2-> phase: 0, arm chosen: 20\n",
            "3-> phase: 0, arm chosen: 30\n",
            "4-> phase: 0, arm chosen: 40\n",
            "5-> phase: 0, arm chosen: 50\n",
            "6-> phase: 0, arm chosen: 10\n",
            "7-> phase: 0, arm chosen: 40\n",
            "8-> phase: 0, arm chosen: 20\n",
            "9-> phase: 0, arm chosen: 5\n",
            "10-> phase: 1, arm chosen: 10\n",
            "11-> phase: 1, arm chosen: 30\n",
            "12-> phase: 1, arm chosen: 40\n",
            "13-> phase: 1, arm chosen: 10\n",
            "14-> phase: 1, arm chosen: 10\n",
            "15-> phase: 1, arm chosen: 50\n",
            "16-> phase: 1, arm chosen: 40\n",
            "17-> phase: 1, arm chosen: 40\n",
            "18-> phase: 1, arm chosen: 40\n",
            "19-> phase: 1, arm chosen: 40\n",
            "20-> phase: 1, arm chosen: 30\n",
            "21-> phase: 1, arm chosen: 5\n",
            "22-> phase: 1, arm chosen: 40\n",
            "23-> phase: 1, arm chosen: 40\n",
            "24-> phase: 1, arm chosen: 50\n",
            "25-> phase: 2, arm chosen: 50\n",
            "26-> phase: 2, arm chosen: 50\n",
            "27-> phase: 2, arm chosen: 5\n",
            "28-> phase: 2, arm chosen: 50\n",
            "29-> phase: 2, arm chosen: 5\n",
            "30-> phase: 2, arm chosen: 10\n",
            "31-> phase: 2, arm chosen: 50\n",
            "32-> phase: 2, arm chosen: 50\n",
            "33-> phase: 2, arm chosen: 50\n",
            "34-> phase: 2, arm chosen: 5\n",
            "35-> phase: 2, arm chosen: 20\n",
            "36-> phase: 3, arm chosen: 20\n",
            "37-> phase: 3, arm chosen: 20\n",
            "38-> phase: 3, arm chosen: 10\n",
            "39-> phase: 3, arm chosen: 40\n",
            "40-> phase: 3, arm chosen: 10\n",
            "41-> phase: 3, arm chosen: 20\n",
            "42-> phase: 3, arm chosen: 30\n",
            "43-> phase: 3, arm chosen: 50\n",
            "44-> phase: 3, arm chosen: 50\n",
            "45-> phase: 3, arm chosen: 5\n",
            "46-> phase: 3, arm chosen: 5\n",
            "47-> phase: 3, arm chosen: 50\n",
            "48-> phase: 4, arm chosen: 20\n",
            "49-> phase: 4, arm chosen: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carlos code"
      ],
      "metadata": {
        "id": "_EDkCnZHb4hA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4rqZLDfiJUq"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import sys\n",
        "import numpy as np\n",
        "import numpy.random as random\n",
        "import matplotlib as mpl\n",
        "\n",
        "mpl.use('pgf')\n",
        "from numpy.random import choice\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "# Utility functions for managing matrices and probability distributions\n",
        "def column(A, j):\n",
        "    return [A[i][j] for i in range(len(A))]\n",
        "\n",
        "\n",
        "def transpose(A):\n",
        "    return [column(A, j) for j in range(len(A[0]))]\n",
        "\n",
        "\n",
        "def distr(weights, gamma=0.0):\n",
        "    weight_sum = float(sum(weights))\n",
        "    return tuple((1.0 - gamma) * (w / weight_sum) + (gamma / len(weights)) for w in weights)\n",
        "\n",
        "\n",
        "def draw(probability_distribution, arms):\n",
        "    arm = choice(arms, size=1, p=probability_distribution, replace=False)[0]\n",
        "    return arm\n",
        "\n",
        "\n",
        "# Implementation of vanilla Exp3\n",
        "def exp3(prices, rewards, gamma, rewardMin=0, rewardMax=1):\n",
        "    weights = [1.0] * numActions\n",
        "    arms = np.array([i for i in range(numActions)])\n",
        "    t = 0\n",
        "    while True:\n",
        "        probabilityDistribution = distr(weights, gamma)\n",
        "        arm = draw(probabilityDistribution, arms)\n",
        "        # Pull arm\n",
        "        reward = rewards(arm, t)\n",
        "        # Scaled to rewards between 0 and 1\n",
        "        normalizedReward = (reward - rewardMin) / (rewardMax - rewardMin)\n",
        "        estimatedReward = float(normalizedReward / probabilityDistribution[arm])\n",
        "        # We update the weight of the chosen arm\n",
        "        weights[arm] = weights[arm] * math.exp(estimatedReward * gamma / numActions)\n",
        "        yield arm, reward, estimatedReward, weights\n",
        "        t = t + 1\n",
        "\n",
        "\n",
        "def runExp3Example():\n",
        "    numActions = 10\n",
        "    numRounds = 100000\n",
        "    rewardVector = []\n",
        "    with open(\"../rewards.txt\", \"r\") as file:\n",
        "        for line in file:\n",
        "            line = line.strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "            if line:\n",
        "                row = [int(num) for num in line.split(\",\")]\n",
        "                rewardVector.append(row)\n",
        "\n",
        "    rewards = lambda arm, t: rewardVector[t][arm]\n",
        "    cumulativeRewards = [sum([rewardVector[t][arm] for t in range(numRounds)]) for arm in range(numActions)]\n",
        "    bestArm = max(range(numActions), key=lambda action: sum([rewardVector[t][action] for t in range(numRounds)]))\n",
        "\n",
        "    # Exact value of Gmax\n",
        "    gMax = cumulativeRewards[bestArm]\n",
        "\n",
        "    # Optimal theoretical gamma\n",
        "    gamma = math.sqrt(numActions * math.log(numActions) / ((math.e - 1) * gMax))\n",
        "\n",
        "    cumulativeReward = 0\n",
        "    bestArmCumulativeReward = 0\n",
        "\n",
        "    # Upper bound of expected regret at each round\n",
        "    regretUpperBound = (math.e - 1) * gamma * gMax + numActions * math.log(numActions) / gamma\n",
        "\n",
        "    with open('exp3results.txt', 'w') as f:\n",
        "        original_stdout = sys.stdout\n",
        "        sys.stdout = f\n",
        "        t = 0\n",
        "        for (arm, reward, est, weights) in exp3(numActions, rewards, gamma):\n",
        "            cumulativeReward += reward\n",
        "            bestArmCumulativeReward += rewardVector[t][bestArm]\n",
        "\n",
        "            weakRegret = (bestArmCumulativeReward - cumulativeReward)\n",
        "            regretBound = 2 * math.sqrt(math.e - 1) * \\\n",
        "                          math.sqrt(bestArmCumulativeReward * numActions * math.log(numActions))\n",
        "            print(\"regret: %d\\tmaxRegret: %.2f\\tweights: (%s)\" % (\n",
        "                weakRegret, regretBound, ', '.join([\"%.3f\" % weight for weight in distr(weights)])))\n",
        "            t = t + 1\n",
        "            if t >= numRounds:\n",
        "                break\n",
        "    sys.stdout = original_stdout\n",
        "    print(\"Cumulative reward: \", cumulativeReward)\n",
        "    print(\"Best arm reward: \", bestArmCumulativeReward)\n",
        "    print(\"Regret:\", cumulativeRewards[bestArm] - cumulativeReward)\n",
        "    print(\"Regret upper bound:\", regretUpperBound)\n",
        "    print(\"Gamma: \", gamma)\n",
        "\n",
        "def regretWeightsGraph(filename, title):\n",
        "    with open(filename, 'r') as infile:\n",
        "        lines = infile.readlines()\n",
        "    lines = [[eval(x.split(\": \")[1]) for x in line.split('\\t')] for line in lines]\n",
        "    data = transpose(lines)\n",
        "    regret = np.array(data[0])\n",
        "    regretBound = np.array(data[1])\n",
        "    weights = np.array(transpose(data[2]))\n",
        "\n",
        "    # Number of rounds\n",
        "    xs = np.array(range(len(data[0])))\n",
        "    ax1 = plt.subplot(211)\n",
        "    plt.ylabel('Cumulative (weak) Regret')\n",
        "    ax1.plot(xs, regret, label=\"Regret \")\n",
        "    ax1.plot(xs, regretBound, label=\"Regret bound\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.title(title)\n",
        "\n",
        "    ax2 = plt.subplot(212)\n",
        "    plt.ylabel('Weight')\n",
        "\n",
        "    for w in weights:\n",
        "        ax2.plot(xs, w)\n",
        "    # plt.show()\n",
        "    # plt.legend(loc=\"upper left\")\n",
        "    plt.savefig('exp3optimal.png', dpi=200)\n",
        "    # plt.savefig('exp3optimal.pgf', format='pgf')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    runExp3Example()\n",
        "    regretWeightsGraph(\"exp3results.txt\", \"Exp3\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r1ZqGFBSiRff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tUdBLFkYnqV6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}